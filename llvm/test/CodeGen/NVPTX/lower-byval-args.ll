; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc < %s -mtriple nvptx -mcpu=sm_20 -verify-machineinstrs | FileCheck %s --check-prefixes=CHECK,CHECK32
; RUN: llc < %s -mtriple nvptx64 -mcpu=sm_20 -verify-machineinstrs | FileCheck %s --check-prefixes=CHECK,CHECK64
; RUN: %if ptxas && !ptxas-12.0 %{ llc < %s -mtriple nvptx -mcpu=sm_20 -verify-machineinstrs | %ptxas-verify %}
; RUN: %if ptxas %{ llc < %s -mtriple nvptx64 -mcpu=sm_20 -verify-machineinstrs | %ptxas-verify %}

%struct.ham = type { [4 x i32] }

; // Verify that load with static offset into parameter is done directly.
; CHECK-LABEL: .visible .entry static_offset
; CHECK-NOT:   .local
; CHECK64: ld.param.u64    [[result_addr:%rd[0-9]+]], [{{.*}}_param_0]
; CHECK64: mov.b64         %[[param_addr:rd[0-9]+]], {{.*}}_param_1
; CHECK64: mov.u64         %[[param_addr1:rd[0-9]+]], %[[param_addr]]
; CHECK64: cvta.to.global.u64 [[result_addr_g:%rd[0-9]+]], [[result_addr]]
;
; CHECK32: ld.param.u32    [[result_addr:%r[0-9]+]], [{{.*}}_param_0]
; CHECK32: mov.b32         %[[param_addr:r[0-9]+]], {{.*}}_param_1
; CHECK32: mov.u32         %[[param_addr1:r[0-9]+]], %[[param_addr]]
; CHECK32: cvta.to.global.u32 [[result_addr_g:%r[0-9]+]], [[result_addr]]
;
; CHECK: ld.param.u32    [[value:%r[0-9]+]], [%[[param_addr1]]+12];
; CHECK: st.global.u32   [[[result_addr_g]]], [[value]];
; Function Attrs: nofree norecurse nounwind willreturn mustprogress
define dso_local void @static_offset(ptr nocapture %arg, ptr nocapture readonly byval(%struct.ham) align 4 %arg1, i32 %arg2) local_unnamed_addr #0 {
; CHECK32-LABEL: static_offset(
; CHECK32:       {
; CHECK32-NEXT:    .reg .pred %p<2>;
; CHECK32-NEXT:    .reg .b32 %r<7>;
; CHECK32-EMPTY:
; CHECK32-NEXT:  // %bb.0: // %bb
; CHECK32-NEXT:    ld.param.u32 %r5, [static_offset_param_2];
; CHECK32-NEXT:    setp.ne.s32 %p1, %r5, 3;
; CHECK32-NEXT:    @%p1 bra $L__BB0_2;
; CHECK32-NEXT:  // %bb.1: // %bb3
; CHECK32-NEXT:    ld.param.u32 %r3, [static_offset_param_0];
; CHECK32-NEXT:    mov.b32 %r4, static_offset_param_1;
; CHECK32-NEXT:    mov.u32 %r1, %r4;
; CHECK32-NEXT:    cvta.to.global.u32 %r2, %r3;
; CHECK32-NEXT:    ld.param.u32 %r6, [%r1+12];
; CHECK32-NEXT:    st.global.u32 [%r2], %r6;
; CHECK32-NEXT:  $L__BB0_2: // %bb6
; CHECK32-NEXT:    ret;
;
; CHECK64-LABEL: static_offset(
; CHECK64:       {
; CHECK64-NEXT:    .reg .pred %p<2>;
; CHECK64-NEXT:    .reg .b32 %r<3>;
; CHECK64-NEXT:    .reg .b64 %rd<5>;
; CHECK64-EMPTY:
; CHECK64-NEXT:  // %bb.0: // %bb
; CHECK64-NEXT:    ld.param.u32 %r1, [static_offset_param_2];
; CHECK64-NEXT:    setp.ne.s32 %p1, %r1, 3;
; CHECK64-NEXT:    @%p1 bra $L__BB0_2;
; CHECK64-NEXT:  // %bb.1: // %bb3
; CHECK64-NEXT:    ld.param.u64 %rd3, [static_offset_param_0];
; CHECK64-NEXT:    mov.b64 %rd4, static_offset_param_1;
; CHECK64-NEXT:    mov.u64 %rd1, %rd4;
; CHECK64-NEXT:    cvta.to.global.u64 %rd2, %rd3;
; CHECK64-NEXT:    ld.param.u32 %r2, [%rd1+12];
; CHECK64-NEXT:    st.global.u32 [%rd2], %r2;
; CHECK64-NEXT:  $L__BB0_2: // %bb6
; CHECK64-NEXT:    ret;
bb:
  %tmp = icmp eq i32 %arg2, 3
  br i1 %tmp, label %bb3, label %bb6

bb3:                                              ; preds = %bb
  %tmp4 = getelementptr inbounds %struct.ham, ptr %arg1, i64 0, i32 0, i64 3
  %tmp5 = load i32, ptr %tmp4, align 4
  store i32 %tmp5, ptr %arg, align 4
  br label %bb6

bb6:                                              ; preds = %bb3, %bb
  ret void
}

; // Verify that load with dynamic offset into parameter is also done directly.
; CHECK-LABEL: .visible .entry dynamic_offset
; CHECK-NOT:   .local
; CHECK64: ld.param.u64    [[result_addr:%rd[0-9]+]], [{{.*}}_param_0]
; CHECK64: mov.b64         %[[param_addr:rd[0-9]+]], {{.*}}_param_1
; CHECK64: mov.u64         %[[param_addr1:rd[0-9]+]], %[[param_addr]]
; CHECK64: cvta.to.global.u64 [[result_addr_g:%rd[0-9]+]], [[result_addr]]
; CHECK64: add.s64         %[[param_w_offset:rd[0-9]+]], %[[param_addr1]],
;
; CHECK32: ld.param.u32    [[result_addr:%r[0-9]+]], [{{.*}}_param_0]
; CHECK32: mov.b32         %[[param_addr:r[0-9]+]], {{.*}}_param_1
; CHECK32: mov.u32         %[[param_addr1:r[0-9]+]], %[[param_addr]]
; CHECK32: cvta.to.global.u32 [[result_addr_g:%r[0-9]+]], [[result_addr]]
; CHECK32: add.s32         %[[param_w_offset:r[0-9]+]], %[[param_addr1]],
;
; CHECK: ld.param.u32    [[value:%r[0-9]+]], [%[[param_w_offset]]];
; CHECK: st.global.u32   [[[result_addr_g]]], [[value]];

; Function Attrs: nofree norecurse nounwind willreturn mustprogress
define dso_local void @dynamic_offset(ptr nocapture %arg, ptr nocapture readonly byval(%struct.ham) align 4 %arg1, i32 %arg2) local_unnamed_addr #0 {
; CHECK32-LABEL: dynamic_offset(
; CHECK32:       {
; CHECK32-NEXT:    .reg .b32 %r<9>;
; CHECK32-EMPTY:
; CHECK32-NEXT:  // %bb.0: // %bb
; CHECK32-NEXT:    ld.param.u32 %r1, [dynamic_offset_param_0];
; CHECK32-NEXT:    mov.b32 %r2, dynamic_offset_param_1;
; CHECK32-NEXT:    mov.u32 %r3, %r2;
; CHECK32-NEXT:    cvta.to.global.u32 %r4, %r1;
; CHECK32-NEXT:    ld.param.u32 %r5, [dynamic_offset_param_2];
; CHECK32-NEXT:    shl.b32 %r6, %r5, 2;
; CHECK32-NEXT:    add.s32 %r7, %r3, %r6;
; CHECK32-NEXT:    ld.param.u32 %r8, [%r7];
; CHECK32-NEXT:    st.global.u32 [%r4], %r8;
; CHECK32-NEXT:    ret;
;
; CHECK64-LABEL: dynamic_offset(
; CHECK64:       {
; CHECK64-NEXT:    .reg .b32 %r<3>;
; CHECK64-NEXT:    .reg .b64 %rd<7>;
; CHECK64-EMPTY:
; CHECK64-NEXT:  // %bb.0: // %bb
; CHECK64-NEXT:    ld.param.u64 %rd1, [dynamic_offset_param_0];
; CHECK64-NEXT:    mov.b64 %rd2, dynamic_offset_param_1;
; CHECK64-NEXT:    mov.u64 %rd3, %rd2;
; CHECK64-NEXT:    cvta.to.global.u64 %rd4, %rd1;
; CHECK64-NEXT:    ld.param.u32 %r1, [dynamic_offset_param_2];
; CHECK64-NEXT:    mul.wide.s32 %rd5, %r1, 4;
; CHECK64-NEXT:    add.s64 %rd6, %rd3, %rd5;
; CHECK64-NEXT:    ld.param.u32 %r2, [%rd6];
; CHECK64-NEXT:    st.global.u32 [%rd4], %r2;
; CHECK64-NEXT:    ret;
bb:
  %tmp = sext i32 %arg2 to i64
  %tmp3 = getelementptr inbounds %struct.ham, ptr %arg1, i64 0, i32 0, i64 %tmp
  %tmp4 = load i32, ptr %tmp3, align 4
  store i32 %tmp4, ptr %arg, align 4
  ret void
}

; Same as above, but with a bitcast present in the chain
; CHECK-LABEL:.visible .entry gep_bitcast
; CHECK-NOT: .local
; CHECK64-DAG: ld.param.u64    [[out:%rd[0-9]+]], [gep_bitcast_param_0]
; CHECK64-DAG: mov.b64         {{%rd[0-9]+}}, gep_bitcast_param_1
;
; CHECK32-DAG: ld.param.u32    [[out:%r[0-9]+]], [gep_bitcast_param_0]
; CHECK32-DAG: mov.b32         {{%r[0-9]+}}, gep_bitcast_param_1
;
; CHECK-DAG: ld.param.u32    {{%r[0-9]+}}, [gep_bitcast_param_2]
; CHECK64:     ld.param.u8     [[value:%rs[0-9]+]], [{{%rd[0-9]+}}]
; CHECK64:     st.global.u8    [{{%rd[0-9]+}}], [[value]];
; CHECK32:     ld.param.u8     [[value:%rs[0-9]+]], [{{%r[0-9]+}}]
; CHECK32:     st.global.u8    [{{%r[0-9]+}}], [[value]];
;
; Function Attrs: nofree norecurse nounwind willreturn mustprogress
define dso_local void @gep_bitcast(ptr nocapture %out,  ptr nocapture readonly byval(%struct.ham) align 4 %in, i32 %n) local_unnamed_addr #0 {
; CHECK32-LABEL: gep_bitcast(
; CHECK32:       {
; CHECK32-NEXT:    .reg .b16 %rs<2>;
; CHECK32-NEXT:    .reg .b32 %r<8>;
; CHECK32-EMPTY:
; CHECK32-NEXT:  // %bb.0: // %bb
; CHECK32-NEXT:    ld.param.u32 %r1, [gep_bitcast_param_0];
; CHECK32-NEXT:    mov.b32 %r2, gep_bitcast_param_1;
; CHECK32-NEXT:    mov.u32 %r3, %r2;
; CHECK32-NEXT:    cvta.to.global.u32 %r4, %r1;
; CHECK32-NEXT:    ld.param.u32 %r5, [gep_bitcast_param_2];
; CHECK32-NEXT:    shl.b32 %r6, %r5, 2;
; CHECK32-NEXT:    add.s32 %r7, %r3, %r6;
; CHECK32-NEXT:    ld.param.u8 %rs1, [%r7];
; CHECK32-NEXT:    st.global.u8 [%r4], %rs1;
; CHECK32-NEXT:    ret;
;
; CHECK64-LABEL: gep_bitcast(
; CHECK64:       {
; CHECK64-NEXT:    .reg .b16 %rs<2>;
; CHECK64-NEXT:    .reg .b32 %r<2>;
; CHECK64-NEXT:    .reg .b64 %rd<7>;
; CHECK64-EMPTY:
; CHECK64-NEXT:  // %bb.0: // %bb
; CHECK64-NEXT:    ld.param.u64 %rd1, [gep_bitcast_param_0];
; CHECK64-NEXT:    mov.b64 %rd2, gep_bitcast_param_1;
; CHECK64-NEXT:    mov.u64 %rd3, %rd2;
; CHECK64-NEXT:    cvta.to.global.u64 %rd4, %rd1;
; CHECK64-NEXT:    ld.param.u32 %r1, [gep_bitcast_param_2];
; CHECK64-NEXT:    mul.wide.s32 %rd5, %r1, 4;
; CHECK64-NEXT:    add.s64 %rd6, %rd3, %rd5;
; CHECK64-NEXT:    ld.param.u8 %rs1, [%rd6];
; CHECK64-NEXT:    st.global.u8 [%rd4], %rs1;
; CHECK64-NEXT:    ret;
bb:
  %n64 = sext i32 %n to i64
  %gep = getelementptr inbounds %struct.ham, ptr %in, i64 0, i32 0, i64 %n64
  %load = load i8, ptr %gep, align 4
  store i8 %load, ptr %out, align 4
  ret void
}

; Same as above, but with an ASC(101) present in the chain
; CHECK-LABEL:.visible .entry gep_bitcast_asc
; CHECK-NOT: .local
; CHECK64-DAG: ld.param.u64    [[out:%rd[0-9]+]], [gep_bitcast_asc_param_0]
; CHECK64-DAG: mov.b64         {{%rd[0-9]+}}, gep_bitcast_asc_param_1
;
; CHECK32-DAG: ld.param.u32    [[out:%r[0-9]+]], [gep_bitcast_asc_param_0]
; CHECK32-DAG: mov.b32         {{%r[0-9]+}}, gep_bitcast_asc_param_1
;
; CHECK-DAG: ld.param.u32    {{%r[0-9]+}}, [gep_bitcast_asc_param_2]
; CHECK64:     ld.param.u8     [[value:%rs[0-9]+]], [{{%rd[0-9]+}}]
; CHECK64:     st.global.u8    [{{%rd[0-9]+}}], [[value]];
; CHECK32:     ld.param.u8     [[value:%rs[0-9]+]], [{{%r[0-9]+}}]
; CHECK32:     st.global.u8    [{{%r[0-9]+}}], [[value]];
;
; Function Attrs: nofree norecurse nounwind willreturn mustprogress
define dso_local void @gep_bitcast_asc(ptr nocapture %out,  ptr nocapture readonly byval(%struct.ham) align 4 %in, i32 %n) local_unnamed_addr #0 {
; CHECK32-LABEL: gep_bitcast_asc(
; CHECK32:       {
; CHECK32-NEXT:    .reg .b16 %rs<2>;
; CHECK32-NEXT:    .reg .b32 %r<8>;
; CHECK32-EMPTY:
; CHECK32-NEXT:  // %bb.0: // %bb
; CHECK32-NEXT:    ld.param.u32 %r1, [gep_bitcast_asc_param_0];
; CHECK32-NEXT:    mov.b32 %r2, gep_bitcast_asc_param_1;
; CHECK32-NEXT:    mov.u32 %r3, %r2;
; CHECK32-NEXT:    cvta.to.global.u32 %r4, %r1;
; CHECK32-NEXT:    ld.param.u32 %r5, [gep_bitcast_asc_param_2];
; CHECK32-NEXT:    shl.b32 %r6, %r5, 2;
; CHECK32-NEXT:    add.s32 %r7, %r3, %r6;
; CHECK32-NEXT:    ld.param.u8 %rs1, [%r7];
; CHECK32-NEXT:    st.global.u8 [%r4], %rs1;
; CHECK32-NEXT:    ret;
;
; CHECK64-LABEL: gep_bitcast_asc(
; CHECK64:       {
; CHECK64-NEXT:    .reg .b16 %rs<2>;
; CHECK64-NEXT:    .reg .b32 %r<2>;
; CHECK64-NEXT:    .reg .b64 %rd<7>;
; CHECK64-EMPTY:
; CHECK64-NEXT:  // %bb.0: // %bb
; CHECK64-NEXT:    ld.param.u64 %rd1, [gep_bitcast_asc_param_0];
; CHECK64-NEXT:    mov.b64 %rd2, gep_bitcast_asc_param_1;
; CHECK64-NEXT:    mov.u64 %rd3, %rd2;
; CHECK64-NEXT:    cvta.to.global.u64 %rd4, %rd1;
; CHECK64-NEXT:    ld.param.u32 %r1, [gep_bitcast_asc_param_2];
; CHECK64-NEXT:    mul.wide.s32 %rd5, %r1, 4;
; CHECK64-NEXT:    add.s64 %rd6, %rd3, %rd5;
; CHECK64-NEXT:    ld.param.u8 %rs1, [%rd6];
; CHECK64-NEXT:    st.global.u8 [%rd4], %rs1;
; CHECK64-NEXT:    ret;
bb:
  %n64 = sext i32 %n to i64
  %gep = getelementptr inbounds %struct.ham, ptr %in, i64 0, i32 0, i64 %n64
  %asc = addrspacecast ptr %gep to ptr addrspace(101)
  %load = load i8, ptr addrspace(101) %asc, align 4
  store i8 %load, ptr %out, align 4
  ret void
}


; Verify that if the pointer escapes, then we do fall back onto using a temp copy.
; CHECK-LABEL: .visible .entry pointer_escapes
; CHECK: .local .align 4 .b8     __local_depot{{.*}}
; CHECK64: ld.param.u64    [[result_addr:%rd[0-9]+]], [{{.*}}_param_0]
; CHECK64: add.u64         %[[copy_addr:rd[0-9]+]], %SPL, 0;
; CHECK32: ld.param.u32    [[result_addr:%r[0-9]+]], [{{.*}}_param_0]
; CHECK32: add.u32         %[[copy_addr:r[0-9]+]], %SPL, 0;
; CHECK-DAG: ld.param.u32    %{{.*}}, [pointer_escapes_param_1+12];
; CHECK-DAG: ld.param.u32    %{{.*}}, [pointer_escapes_param_1+8];
; CHECK-DAG: ld.param.u32    %{{.*}}, [pointer_escapes_param_1+4];
; CHECK-DAG: ld.param.u32    %{{.*}}, [pointer_escapes_param_1];
; CHECK-DAG: st.local.u32    [%[[copy_addr]]+12],
; CHECK-DAG: st.local.u32    [%[[copy_addr]]+8],
; CHECK-DAG: st.local.u32    [%[[copy_addr]]+4],
; CHECK-DAG: st.local.u32    [%[[copy_addr]]],
; CHECK64: cvta.to.global.u64 [[result_addr_g:%rd[0-9]+]], [[result_addr]]
; CHECK64: add.s64         %[[copy_w_offset:rd[0-9]+]], %[[copy_addr]],
; CHECK32: cvta.to.global.u32 [[result_addr_g:%r[0-9]+]], [[result_addr]]
; CHECK32: add.s32         %[[copy_w_offset:r[0-9]+]], %[[copy_addr]],
; CHECK: ld.local.u32    [[value:%r[0-9]+]], [%[[copy_w_offset]]];
; CHECK: st.global.u32   [[[result_addr_g]]], [[value]];

; Function Attrs: convergent norecurse nounwind mustprogress
define dso_local void @pointer_escapes(ptr nocapture %arg, ptr byval(%struct.ham) align 4 %arg1, i32 %arg2) local_unnamed_addr #1 {
; CHECK32-LABEL: pointer_escapes(
; CHECK32:       {
; CHECK32-NEXT:    .local .align 4 .b8 __local_depot4[16];
; CHECK32-NEXT:    .reg .b32 %SP;
; CHECK32-NEXT:    .reg .b32 %SPL;
; CHECK32-NEXT:    .reg .b32 %r<16>;
; CHECK32-EMPTY:
; CHECK32-NEXT:  // %bb.0: // %bb
; CHECK32-NEXT:    mov.u32 %SPL, __local_depot4;
; CHECK32-NEXT:    ld.param.u32 %r1, [pointer_escapes_param_0];
; CHECK32-NEXT:    add.u32 %r3, %SPL, 0;
; CHECK32-NEXT:    ld.param.u32 %r4, [pointer_escapes_param_2];
; CHECK32-NEXT:    ld.param.u32 %r5, [pointer_escapes_param_1+12];
; CHECK32-NEXT:    ld.param.u32 %r6, [pointer_escapes_param_1+8];
; CHECK32-NEXT:    ld.param.u32 %r7, [pointer_escapes_param_1+4];
; CHECK32-NEXT:    ld.param.u32 %r8, [pointer_escapes_param_1];
; CHECK32-NEXT:    st.local.u32 [%r3], %r8;
; CHECK32-NEXT:    st.local.u32 [%r3+4], %r7;
; CHECK32-NEXT:    st.local.u32 [%r3+8], %r6;
; CHECK32-NEXT:    st.local.u32 [%r3+12], %r5;
; CHECK32-NEXT:    cvta.to.global.u32 %r9, %r1;
; CHECK32-NEXT:    shl.b32 %r10, %r4, 2;
; CHECK32-NEXT:    add.s32 %r11, %r3, %r10;
; CHECK32-NEXT:    cvta.local.u32 %r12, %r11;
; CHECK32-NEXT:    ld.local.u32 %r13, [%r11];
; CHECK32-NEXT:    st.global.u32 [%r9], %r13;
; CHECK32-NEXT:    { // callseq 0, 0
; CHECK32-NEXT:    .param .b32 param0;
; CHECK32-NEXT:    st.param.b32 [param0+0], %r12;
; CHECK32-NEXT:    .param .b32 retval0;
; CHECK32-NEXT:    call.uni (retval0),
; CHECK32-NEXT:    escape,
; CHECK32-NEXT:    (
; CHECK32-NEXT:    param0
; CHECK32-NEXT:    );
; CHECK32-NEXT:    ld.param.b32 %r14, [retval0+0];
; CHECK32-NEXT:    } // callseq 0
; CHECK32-NEXT:    ret;
;
; CHECK64-LABEL: pointer_escapes(
; CHECK64:       {
; CHECK64-NEXT:    .local .align 4 .b8 __local_depot4[16];
; CHECK64-NEXT:    .reg .b64 %SP;
; CHECK64-NEXT:    .reg .b64 %SPL;
; CHECK64-NEXT:    .reg .b32 %r<7>;
; CHECK64-NEXT:    .reg .b64 %rd<10>;
; CHECK64-EMPTY:
; CHECK64-NEXT:  // %bb.0: // %bb
; CHECK64-NEXT:    mov.u64 %SPL, __local_depot4;
; CHECK64-NEXT:    ld.param.u64 %rd1, [pointer_escapes_param_0];
; CHECK64-NEXT:    add.u64 %rd3, %SPL, 0;
; CHECK64-NEXT:    ld.param.u32 %r1, [pointer_escapes_param_2];
; CHECK64-NEXT:    ld.param.u32 %r2, [pointer_escapes_param_1+12];
; CHECK64-NEXT:    ld.param.u32 %r3, [pointer_escapes_param_1+8];
; CHECK64-NEXT:    ld.param.u32 %r4, [pointer_escapes_param_1+4];
; CHECK64-NEXT:    ld.param.u32 %r5, [pointer_escapes_param_1];
; CHECK64-NEXT:    st.local.u32 [%rd3], %r5;
; CHECK64-NEXT:    st.local.u32 [%rd3+4], %r4;
; CHECK64-NEXT:    st.local.u32 [%rd3+8], %r3;
; CHECK64-NEXT:    st.local.u32 [%rd3+12], %r2;
; CHECK64-NEXT:    cvta.to.global.u64 %rd4, %rd1;
; CHECK64-NEXT:    mul.wide.s32 %rd5, %r1, 4;
; CHECK64-NEXT:    add.s64 %rd6, %rd3, %rd5;
; CHECK64-NEXT:    cvta.local.u64 %rd7, %rd6;
; CHECK64-NEXT:    ld.local.u32 %r6, [%rd6];
; CHECK64-NEXT:    st.global.u32 [%rd4], %r6;
; CHECK64-NEXT:    { // callseq 0, 0
; CHECK64-NEXT:    .param .b64 param0;
; CHECK64-NEXT:    st.param.b64 [param0+0], %rd7;
; CHECK64-NEXT:    .param .b64 retval0;
; CHECK64-NEXT:    call.uni (retval0),
; CHECK64-NEXT:    escape,
; CHECK64-NEXT:    (
; CHECK64-NEXT:    param0
; CHECK64-NEXT:    );
; CHECK64-NEXT:    ld.param.b64 %rd8, [retval0+0];
; CHECK64-NEXT:    } // callseq 0
; CHECK64-NEXT:    ret;
bb:
  %tmp = sext i32 %arg2 to i64
  %tmp3 = getelementptr inbounds %struct.ham, ptr %arg1, i64 0, i32 0, i64 %tmp
  %tmp4 = load i32, ptr %tmp3, align 4
  store i32 %tmp4, ptr %arg, align 4
  %tmp5 = call ptr @escape(ptr nonnull %tmp3) #3
  ret void
}

; Function Attrs: convergent nounwind
declare dso_local ptr @escape(ptr) local_unnamed_addr


!llvm.module.flags = !{!0, !1, !2}
!nvvm.annotations = !{!3, !4, !5, !6, !7}

!0 = !{i32 2, !"SDK Version", [2 x i32] [i32 9, i32 1]}
!1 = !{i32 1, !"wchar_size", i32 4}
!2 = !{i32 4, !"nvvm-reflect-ftz", i32 0}
!3 = !{ptr @static_offset, !"kernel", i32 1}
!4 = !{ptr @dynamic_offset, !"kernel", i32 1}
!5 = !{ptr @pointer_escapes, !"kernel", i32 1}
!6 = !{ptr @gep_bitcast, !"kernel", i32 1}
!7 = !{ptr @gep_bitcast_asc, !"kernel", i32 1}
;; NOTE: These prefixes are unused and the list is autogenerated. Do not add tests below this line:
; CHECK: {{.*}}
