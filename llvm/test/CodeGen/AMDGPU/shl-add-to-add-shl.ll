; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 4
; RUN: llc -mtriple=amdgcn -mcpu=fiji < %s | FileCheck %s

; Check transformation shl (or|add x, c2), c1 => or|add (shl x, c1), (c2 << c1)
; Only one shift if expected, GEP shall not produce a separate shift

; CHECK-LABEL: {{^}}add_const_offset:
; CHECK: v_lshlrev_b32_e32 v[[SHL:[0-9]+]], 4, v0
; CHECK: v_add_u32_e32 v[[ADD:[0-9]+]], vcc, 0xc80, v[[SHL]]
; CHECK-NOT: v_lshl
; CHECK: v_add_u32_e32 v[[ADDRLO:[0-9]+]], vcc, s{{[0-9]+}}, v[[ADD]]
; CHECK: load_dword v{{[0-9]+}}, v[[[ADDRLO]]:
define amdgpu_kernel void @add_const_offset(ptr addrspace(1) nocapture %arg) {
; CHECK-LABEL: add_const_offset:
; CHECK:       ; %bb.0: ; %bb
; CHECK-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; CHECK-NEXT:    v_lshlrev_b32_e32 v0, 4, v0
; CHECK-NEXT:    v_add_u32_e32 v0, vcc, 0xc80, v0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v1, s1
; CHECK-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; CHECK-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; CHECK-NEXT:    flat_load_dword v2, v[0:1]
; CHECK-NEXT:    v_mov_b32_e32 v0, s0
; CHECK-NEXT:    v_mov_b32_e32 v1, s1
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    flat_store_dword v[0:1], v2
; CHECK-NEXT:    s_endpgm
bb:
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %add = add i32 %id, 200
  %shl = shl i32 %add, 2
  %ptr = getelementptr inbounds i32, ptr addrspace(1) %arg, i32 %shl
  %val = load i32, ptr addrspace(1) %ptr, align 4
  store i32 %val, ptr addrspace(1) %arg, align 4
  ret void
}

; CHECK-LABEL: {{^}}or_const_offset:
; CHECK: v_lshlrev_b32_e32 v[[SHL:[0-9]+]], 4, v0
; CHECK: v_or_b32_e32 v[[OR:[0-9]+]], 0x1000, v[[SHL]]
; CHECK-NOT: v_lshl
; CHECK: v_add_u32_e32 v[[ADDRLO:[0-9]+]], vcc, s{{[0-9]+}}, v[[OR]]
; CHECK: load_dword v{{[0-9]+}}, v[[[ADDRLO]]:
define amdgpu_kernel void @or_const_offset(ptr addrspace(1) nocapture %arg) {
; CHECK-LABEL: or_const_offset:
; CHECK:       ; %bb.0: ; %bb
; CHECK-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; CHECK-NEXT:    v_lshlrev_b32_e32 v0, 4, v0
; CHECK-NEXT:    v_or_b32_e32 v0, 0x1000, v0
; CHECK-NEXT:    s_waitcnt lgkmcnt(0)
; CHECK-NEXT:    v_mov_b32_e32 v1, s1
; CHECK-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; CHECK-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; CHECK-NEXT:    flat_load_dword v2, v[0:1]
; CHECK-NEXT:    v_mov_b32_e32 v0, s0
; CHECK-NEXT:    v_mov_b32_e32 v1, s1
; CHECK-NEXT:    s_waitcnt vmcnt(0)
; CHECK-NEXT:    flat_store_dword v[0:1], v2
; CHECK-NEXT:    s_endpgm
bb:
  %id = tail call i32 @llvm.amdgcn.workitem.id.x()
  %add = or i32 %id, 256
  %shl = shl i32 %add, 2
  %ptr = getelementptr inbounds i32, ptr addrspace(1) %arg, i32 %shl
  %val = load i32, ptr addrspace(1) %ptr, align 4
  store i32 %val, ptr addrspace(1) %arg, align 4
  ret void
}

declare i32 @llvm.amdgcn.workitem.id.x()
