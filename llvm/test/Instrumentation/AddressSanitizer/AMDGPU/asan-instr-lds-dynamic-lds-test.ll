; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 4
; RUN: opt < %s -passes=asan -S -mtriple=amdgcn-- | FileCheck %s

%llvm.amdgcn.sw.lds.k0.md.type = type { %llvm.amdgcn.sw.lds.k0.md.item, %llvm.amdgcn.sw.lds.k0.md.item }
%llvm.amdgcn.sw.lds.k0.md.item = type { i32, i32, i32 }

@llvm.amdgcn.sw.lds.k0 = internal addrspace(3) global ptr poison, align 1
@llvm.amdgcn.sw.lds.k0.md = internal addrspace(1) global %llvm.amdgcn.sw.lds.k0.md.type zeroinitializer, no_sanitize_address

define amdgpu_kernel void @k0() sanitize_address {
; CHECK-LABEL: define amdgpu_kernel void @k0(
; CHECK-SAME: ) #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  WId:
; CHECK-NEXT:    [[TMP0:%.*]] = call i32 @llvm.amdgcn.workitem.id.x()
; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @llvm.amdgcn.workitem.id.y()
; CHECK-NEXT:    [[TMP2:%.*]] = call i32 @llvm.amdgcn.workitem.id.z()
; CHECK-NEXT:    [[TMP3:%.*]] = or i32 [[TMP0]], [[TMP1]]
; CHECK-NEXT:    [[TMP4:%.*]] = or i32 [[TMP3]], [[TMP2]]
; CHECK-NEXT:    [[TMP5:%.*]] = icmp eq i32 [[TMP4]], 0
; CHECK-NEXT:    br i1 [[TMP5]], label [[MALLOC:%.*]], label [[TMP19:%.*]]
; CHECK:       Malloc:
; CHECK-NEXT:    [[TMP6:%.*]] = call ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds ptr addrspace(4), ptr addrspace(4) [[TMP6]], i32 15
; CHECK-NEXT:    store i64 0, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, align 8
; CHECK-NEXT:    [[TMP25:%.*]] = ptrtoint ptr addrspace(4) [[TMP7]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = lshr i64 [[TMP25]], 3
; CHECK-NEXT:    [[TMP27:%.*]] = add i64 [[TMP26]], 2147450880
; CHECK-NEXT:    [[TMP28:%.*]] = inttoptr i64 [[TMP27]] to ptr
; CHECK-NEXT:    [[TMP29:%.*]] = load i8, ptr [[TMP28]], align 1
; CHECK-NEXT:    [[TMP30:%.*]] = icmp ne i8 [[TMP29]], 0
; CHECK-NEXT:    [[TMP31:%.*]] = call i64 @llvm.amdgcn.ballot.i64(i1 [[TMP30]])
; CHECK-NEXT:    [[TMP32:%.*]] = icmp ne i64 [[TMP31]], 0
; CHECK-NEXT:    br i1 [[TMP32]], label [[ASAN_REPORT:%.*]], label [[TMP33:%.*]], !prof [[PROF0:![0-9]+]]
; CHECK:       asan.report:
; CHECK-NEXT:    br i1 [[TMP30]], label [[TMP34:%.*]], label [[TMP65:%.*]]
; CHECK:       16:
; CHECK-NEXT:    call void @__asan_report_load8(i64 [[TMP25]]) #[[ATTR6:[0-9]+]]
; CHECK-NEXT:    call void @llvm.amdgcn.unreachable()
; CHECK-NEXT:    br label [[TMP65]]
; CHECK:       17:
; CHECK-NEXT:    br label [[TMP33]]
; CHECK:       18:
; CHECK-NEXT:    [[TMP8:%.*]] = load i64, ptr addrspace(4) [[TMP7]], align 8
; CHECK-NEXT:    store i64 [[TMP8]], ptr addrspace(1) getelementptr inbounds ([[TMP0]], ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 0, i32 1), align 8
; CHECK-NEXT:    [[TMP9:%.*]] = add i64 [[TMP8]], 0
; CHECK-NEXT:    [[TMP10:%.*]] = udiv i64 [[TMP9]], 1
; CHECK-NEXT:    [[TMP11:%.*]] = mul i64 [[TMP10]], 1
; CHECK-NEXT:    store i64 [[TMP11]], ptr addrspace(1) getelementptr inbounds ([[TMP0]], ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 0, i32 2), align 8
; CHECK-NEXT:    [[TMP12:%.*]] = add i64 0, [[TMP11]]
; CHECK-NEXT:    store i64 [[TMP12]], ptr addrspace(1) getelementptr inbounds ([[TMP0]], ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 0), align 8
; CHECK-NEXT:    [[TMP13:%.*]] = load i64, ptr addrspace(4) [[TMP7]], align 8
; CHECK-NEXT:    store i64 [[TMP13]], ptr addrspace(1) getelementptr inbounds ([[TMP0]], ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 1), align 8
; CHECK-NEXT:    [[TMP14:%.*]] = add i64 [[TMP13]], 0
; CHECK-NEXT:    [[TMP15:%.*]] = udiv i64 [[TMP14]], 1
; CHECK-NEXT:    [[TMP16:%.*]] = mul i64 [[TMP15]], 1
; CHECK-NEXT:    store i64 [[TMP16]], ptr addrspace(1) getelementptr inbounds ([[TMP0]], ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 2), align 8
; CHECK-NEXT:    [[TMP17:%.*]] = add i64 [[TMP12]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = call ptr addrspace(1) @malloc(i64 [[TMP17]])
; CHECK-NEXT:    store ptr addrspace(1) [[TMP18]], ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, align 8
; CHECK-NEXT:    br label [[TMP19]]
; CHECK:       30:
; CHECK-NEXT:    [[XYZCOND:%.*]] = phi i1 [ false, [[WID:%.*]] ], [ true, [[TMP33]] ]
; CHECK-NEXT:    call void @llvm.amdgcn.s.barrier()
; CHECK-NEXT:    [[TMP20:%.*]] = load i32, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, align 4
; CHECK-NEXT:    [[TMP21:%.*]] = getelementptr inbounds i8, ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, i32 [[TMP20]]
; CHECK-NEXT:    [[TMP22:%.*]] = load i32, ptr addrspace(1) getelementptr inbounds ([[TMP0]], ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 0), align 4
; CHECK-NEXT:    [[TMP23:%.*]] = getelementptr inbounds i8, ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, i32 [[TMP22]]
; CHECK-NEXT:    [[TMP35:%.*]] = ptrtoint ptr addrspace(3) [[TMP21]] to i64
; CHECK-NEXT:    [[TMP36:%.*]] = lshr i64 [[TMP35]], 3
; CHECK-NEXT:    [[TMP37:%.*]] = add i64 [[TMP36]], 2147450880
; CHECK-NEXT:    [[TMP38:%.*]] = inttoptr i64 [[TMP37]] to ptr
; CHECK-NEXT:    [[TMP39:%.*]] = load i8, ptr [[TMP38]], align 1
; CHECK-NEXT:    [[TMP40:%.*]] = icmp ne i8 [[TMP39]], 0
; CHECK-NEXT:    [[TMP41:%.*]] = and i64 [[TMP35]], 7
; CHECK-NEXT:    [[TMP42:%.*]] = trunc i64 [[TMP41]] to i8
; CHECK-NEXT:    [[TMP43:%.*]] = icmp sge i8 [[TMP42]], [[TMP39]]
; CHECK-NEXT:    [[TMP44:%.*]] = and i1 [[TMP40]], [[TMP43]]
; CHECK-NEXT:    [[TMP45:%.*]] = call i64 @llvm.amdgcn.ballot.i64(i1 [[TMP44]])
; CHECK-NEXT:    [[TMP46:%.*]] = icmp ne i64 [[TMP45]], 0
; CHECK-NEXT:    br i1 [[TMP46]], label [[ASAN_REPORT1:%.*]], label [[TMP49:%.*]], !prof [[PROF0]]
; CHECK:       asan.report1:
; CHECK-NEXT:    br i1 [[TMP44]], label [[TMP47:%.*]], label [[TMP48:%.*]]
; CHECK:       47:
; CHECK-NEXT:    call void @__asan_report_store1(i64 [[TMP35]]) #[[ATTR6]]
; CHECK-NEXT:    call void @llvm.amdgcn.unreachable()
; CHECK-NEXT:    br label [[TMP48]]
; CHECK:       48:
; CHECK-NEXT:    br label [[TMP49]]
; CHECK:       49:
; CHECK-NEXT:    store i8 7, ptr addrspace(3) [[TMP21]], align 4
; CHECK-NEXT:    [[TMP50:%.*]] = ptrtoint ptr addrspace(3) [[TMP23]] to i64
; CHECK-NEXT:    [[TMP51:%.*]] = lshr i64 [[TMP50]], 3
; CHECK-NEXT:    [[TMP52:%.*]] = add i64 [[TMP51]], 2147450880
; CHECK-NEXT:    [[TMP53:%.*]] = inttoptr i64 [[TMP52]] to ptr
; CHECK-NEXT:    [[TMP54:%.*]] = load i8, ptr [[TMP53]], align 1
; CHECK-NEXT:    [[TMP55:%.*]] = icmp ne i8 [[TMP54]], 0
; CHECK-NEXT:    [[TMP56:%.*]] = and i64 [[TMP50]], 7
; CHECK-NEXT:    [[TMP57:%.*]] = trunc i64 [[TMP56]] to i8
; CHECK-NEXT:    [[TMP58:%.*]] = icmp sge i8 [[TMP57]], [[TMP54]]
; CHECK-NEXT:    [[TMP59:%.*]] = and i1 [[TMP55]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = call i64 @llvm.amdgcn.ballot.i64(i1 [[TMP59]])
; CHECK-NEXT:    [[TMP61:%.*]] = icmp ne i64 [[TMP60]], 0
; CHECK-NEXT:    br i1 [[TMP61]], label [[ASAN_REPORT2:%.*]], label [[TMP64:%.*]], !prof [[PROF0]]
; CHECK:       asan.report2:
; CHECK-NEXT:    br i1 [[TMP59]], label [[TMP62:%.*]], label [[TMP63:%.*]]
; CHECK:       62:
; CHECK-NEXT:    call void @__asan_report_store1(i64 [[TMP50]]) #[[ATTR6]]
; CHECK-NEXT:    call void @llvm.amdgcn.unreachable()
; CHECK-NEXT:    br label [[TMP63]]
; CHECK:       63:
; CHECK-NEXT:    br label [[TMP64]]
; CHECK:       64:
; CHECK-NEXT:    store i8 8, ptr addrspace(3) [[TMP23]], align 8
; CHECK-NEXT:    br label [[CONDFREE:%.*]]
; CHECK:       CondFree:
; CHECK-NEXT:    call void @llvm.amdgcn.s.barrier()
; CHECK-NEXT:    br i1 [[XYZCOND]], label [[FREE:%.*]], label [[END:%.*]]
; CHECK:       Free:
; CHECK-NEXT:    [[TMP24:%.*]] = load ptr, ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, align 8
; CHECK-NEXT:    call void @free(ptr [[TMP24]])
; CHECK-NEXT:    br label [[END]]
; CHECK:       End:
; CHECK-NEXT:    ret void
;
WId:
  %0 = call i32 @llvm.amdgcn.workitem.id.x()
  %1 = call i32 @llvm.amdgcn.workitem.id.y()
  %2 = call i32 @llvm.amdgcn.workitem.id.z()
  %3 = or i32 %0, %1
  %4 = or i32 %3, %2
  %5 = icmp eq i32 %4, 0
  br i1 %5, label %Malloc, label %19

Malloc:                                           ; preds = %WId
  %6 = call ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr()
  %7 = getelementptr inbounds ptr addrspace(4), ptr addrspace(4) %6, i32 15
  store i64 0, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, align 8
  %8 = load i64, ptr addrspace(4) %7, align 8
  store i64 %8, ptr addrspace(1) getelementptr inbounds (%llvm.amdgcn.sw.lds.k0.md.type, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 0, i32 1), align 8
  %9 = add i64 %8, 0
  %10 = udiv i64 %9, 1
  %11 = mul i64 %10, 1
  store i64 %11, ptr addrspace(1) getelementptr inbounds (%llvm.amdgcn.sw.lds.k0.md.type, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 0, i32 2), align 8
  %12 = add i64 0, %11
  store i64 %12, ptr addrspace(1) getelementptr inbounds (%llvm.amdgcn.sw.lds.k0.md.type, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 0), align 8
  %13 = load i64, ptr addrspace(4) %7, align 8
  store i64 %13, ptr addrspace(1) getelementptr inbounds (%llvm.amdgcn.sw.lds.k0.md.type, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 1), align 8
  %14 = add i64 %13, 0
  %15 = udiv i64 %14, 1
  %16 = mul i64 %15, 1
  store i64 %16, ptr addrspace(1) getelementptr inbounds (%llvm.amdgcn.sw.lds.k0.md.type, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 2), align 8
  %17 = add i64 %12, %16
  %18 = call ptr addrspace(1) @malloc(i64 %17)
  store ptr addrspace(1) %18, ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, align 8
  br label %19

19:                                               ; preds = %Malloc, %WId
  %xyzCond = phi i1 [ false, %WId ], [ true, %Malloc ]
  call void @llvm.amdgcn.s.barrier()
  %20 = load i32, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, align 4
  %21 = getelementptr inbounds i8, ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, i32 %20
  %22 = load i32, ptr addrspace(1) getelementptr inbounds (%llvm.amdgcn.sw.lds.k0.md.type, ptr addrspace(1) @llvm.amdgcn.sw.lds.k0.md, i32 0, i32 1, i32 0), align 4
  %23 = getelementptr inbounds i8, ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, i32 %22
  store i8 7, ptr addrspace(3) %21, align 4
  store i8 8, ptr addrspace(3) %23, align 8
  br label %CondFree

CondFree:                                         ; preds = %19
  call void @llvm.amdgcn.s.barrier()
  br i1 %xyzCond, label %Free, label %End

Free:                                             ; preds = %CondFree
  %24 = load ptr, ptr addrspace(3) @llvm.amdgcn.sw.lds.k0, align 8
  call void @free(ptr %24)
  br label %End

End:                                              ; preds = %Free, %CondFree
  ret void
}

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.x() #0

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.y() #0

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i32 @llvm.amdgcn.workitem.id.z() #0

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare align 4 ptr addrspace(4) @llvm.amdgcn.implicitarg.ptr() #0

declare ptr addrspace(1) @malloc(i64)

; Function Attrs: convergent nocallback nofree nounwind willreturn
declare void @llvm.amdgcn.s.barrier() #1

declare void @free(ptr)

attributes #0 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #1 = { convergent nocallback nofree nounwind willreturn }
;.
; CHECK: [[PROF0]] = !{!"branch_weights", i32 1, i32 100000}
;.
