// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// REQUIRES: riscv-registered-target
// RUN: %clang_cc1 -triple riscv32 -target-feature +v -O2 -emit-llvm %s -o - \
// RUN:     |  FileCheck --check-prefix=RV32 %s
// RUN: %clang_cc1 -triple riscv64 -target-feature +v -O2 -emit-llvm %s -o - \
// RUN:     |  FileCheck --check-prefix=RV64 %s
// RUN: %clang_cc1 -triple riscv32 -target-feature +v -O2 -emit-llvm %s -o - \
// RUN:     -mvscale-min=2 -mvscale-max=2 \
// RUN:     | FileCheck --check-prefix=RV32-FIXED %s
// RUN: %clang_cc1 -triple riscv64 -target-feature +v -O2 -emit-llvm %s -o - \
// RUN:     -mvscale-min=2 -mvscale-max=2 \
// RUN:     | FileCheck --check-prefix=RV64-FIXED %s

#include <riscv_vector.h>

inline void test_vsetvlmax(void *data, size_t len) {
  uint8_t *ptr = (uint8_t *)data;
  size_t vl = __riscv_vsetvlmax_e8m1();
  vuint8m1_t zero = __riscv_vmv_v_x_u8m1(0, vl);
  while (len > vl) {
    __riscv_vse8(ptr, zero, vl);
    ptr += vl;
    len -= vl;
  }
  __riscv_vse8(ptr, zero, len);
}

inline void test_vsetvli(void *data, size_t len) {
  uint8_t *ptr = (uint8_t *)data;
  size_t vl = __riscv_vsetvl_e8m1(len);
  while (len > 0) {
    vuint8m1_t zero = __riscv_vmv_v_x_u8m1(0, vl);
    __riscv_vse8(ptr, zero, vl);
    ptr += vl;
    len -= vl;
    vl = __riscv_vsetvl_e8m1(len);
  }
}

// RV32-LABEL: @test_vsetvlmax_known_vl(
// RV32-NEXT:  test_vsetvlmax.exit:
// RV32-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvlimax.i32(i32 0, i32 0)
// RV32-NEXT:    [[TMP0:%.*]] = icmp ugt i32 [[VL1_I]], 15
// RV32-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV32-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 [[VL1_I]])
// RV32-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i32 8)
// RV32-NEXT:    ret void
//
// RV64-LABEL: @test_vsetvlmax_known_vl(
// RV64-NEXT:  test_vsetvlmax.exit:
// RV64-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvlimax.i64(i64 0, i64 0)
// RV64-NEXT:    [[TMP0:%.*]] = icmp ugt i64 [[VL1_I]], 15
// RV64-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV64-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 [[VL1_I]])
// RV64-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i64 8)
// RV64-NEXT:    ret void
//
// RV32-FIXED-LABEL: @test_vsetvlmax_known_vl(
// RV32-FIXED-NEXT:  entry:
// RV32-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvlimax.i32(i32 0, i32 0)
// RV32-FIXED-NEXT:    [[TMP0:%.*]] = icmp eq i32 [[VL1_I]], 16
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV32-FIXED-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 16)
// RV32-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i32 8)
// RV32-FIXED-NEXT:    ret void
//
// RV64-FIXED-LABEL: @test_vsetvlmax_known_vl(
// RV64-FIXED-NEXT:  entry:
// RV64-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvlimax.i64(i64 0, i64 0)
// RV64-FIXED-NEXT:    [[TMP0:%.*]] = icmp eq i64 [[VL1_I]], 16
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV64-FIXED-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 16)
// RV64-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i64 8)
// RV64-FIXED-NEXT:    ret void
//
void test_vsetvlmax_known_vl(uint64_t* data) { test_vsetvlmax(data, sizeof(uint64_t)); }

// RV32-LABEL: @test_vsetvlmax_agnostic_vl(
// RV32-NEXT:  entry:
// RV32-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvlimax.i32(i32 0, i32 0)
// RV32-NEXT:    [[TMP0:%.*]] = icmp ugt i32 [[VL1_I]], 15
// RV32-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV32-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 [[VL1_I]])
// RV32-NEXT:    [[CMP10_I:%.*]] = icmp ult i32 [[VL1_I]], [[LEN:%.*]]
// RV32-NEXT:    br i1 [[CMP10_I]], label [[WHILE_BODY_I:%.*]], label [[TEST_VSETVLMAX_EXIT:%.*]]
// RV32:       while.body.i:
// RV32-NEXT:    [[LEN_ADDR_012_I:%.*]] = phi i32 [ [[SUB_I:%.*]], [[WHILE_BODY_I]] ], [ [[LEN]], [[ENTRY:%.*]] ]
// RV32-NEXT:    [[PTR_011_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[WHILE_BODY_I]] ], [ [[DATA:%.*]], [[ENTRY]] ]
// RV32-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_011_I]], i32 [[VL1_I]])
// RV32-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_011_I]], i32 [[VL1_I]]
// RV32-NEXT:    [[SUB_I]] = sub i32 [[LEN_ADDR_012_I]], [[VL1_I]]
// RV32-NEXT:    [[CMP_I:%.*]] = icmp ugt i32 [[SUB_I]], [[VL1_I]]
// RV32-NEXT:    br i1 [[CMP_I]], label [[WHILE_BODY_I]], label [[TEST_VSETVLMAX_EXIT]], !llvm.loop [[LOOP4:![0-9]+]]
// RV32:       test_vsetvlmax.exit:
// RV32-NEXT:    [[PTR_0_LCSSA_I:%.*]] = phi ptr [ [[DATA]], [[ENTRY]] ], [ [[ADD_PTR_I]], [[WHILE_BODY_I]] ]
// RV32-NEXT:    [[LEN_ADDR_0_LCSSA_I:%.*]] = phi i32 [ [[LEN]], [[ENTRY]] ], [ [[SUB_I]], [[WHILE_BODY_I]] ]
// RV32-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_0_LCSSA_I]], i32 [[LEN_ADDR_0_LCSSA_I]])
// RV32-NEXT:    ret void
//
// RV64-LABEL: @test_vsetvlmax_agnostic_vl(
// RV64-NEXT:  entry:
// RV64-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvlimax.i64(i64 0, i64 0)
// RV64-NEXT:    [[TMP0:%.*]] = icmp ugt i64 [[VL1_I]], 15
// RV64-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV64-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 [[VL1_I]])
// RV64-NEXT:    [[CMP10_I:%.*]] = icmp ult i64 [[VL1_I]], [[LEN:%.*]]
// RV64-NEXT:    br i1 [[CMP10_I]], label [[WHILE_BODY_I:%.*]], label [[TEST_VSETVLMAX_EXIT:%.*]]
// RV64:       while.body.i:
// RV64-NEXT:    [[LEN_ADDR_012_I:%.*]] = phi i64 [ [[SUB_I:%.*]], [[WHILE_BODY_I]] ], [ [[LEN]], [[ENTRY:%.*]] ]
// RV64-NEXT:    [[PTR_011_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[WHILE_BODY_I]] ], [ [[DATA:%.*]], [[ENTRY]] ]
// RV64-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_011_I]], i64 [[VL1_I]])
// RV64-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_011_I]], i64 [[VL1_I]]
// RV64-NEXT:    [[SUB_I]] = sub i64 [[LEN_ADDR_012_I]], [[VL1_I]]
// RV64-NEXT:    [[CMP_I:%.*]] = icmp ugt i64 [[SUB_I]], [[VL1_I]]
// RV64-NEXT:    br i1 [[CMP_I]], label [[WHILE_BODY_I]], label [[TEST_VSETVLMAX_EXIT]], !llvm.loop [[LOOP4:![0-9]+]]
// RV64:       test_vsetvlmax.exit:
// RV64-NEXT:    [[PTR_0_LCSSA_I:%.*]] = phi ptr [ [[DATA]], [[ENTRY]] ], [ [[ADD_PTR_I]], [[WHILE_BODY_I]] ]
// RV64-NEXT:    [[LEN_ADDR_0_LCSSA_I:%.*]] = phi i64 [ [[LEN]], [[ENTRY]] ], [ [[SUB_I]], [[WHILE_BODY_I]] ]
// RV64-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_0_LCSSA_I]], i64 [[LEN_ADDR_0_LCSSA_I]])
// RV64-NEXT:    ret void
//
// RV32-FIXED-LABEL: @test_vsetvlmax_agnostic_vl(
// RV32-FIXED-NEXT:  entry:
// RV32-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvlimax.i32(i32 0, i32 0)
// RV32-FIXED-NEXT:    [[TMP0:%.*]] = icmp eq i32 [[VL1_I]], 16
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV32-FIXED-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 16)
// RV32-FIXED-NEXT:    [[CMP10_I:%.*]] = icmp ugt i32 [[LEN:%.*]], 16
// RV32-FIXED-NEXT:    br i1 [[CMP10_I]], label [[WHILE_BODY_I:%.*]], label [[TEST_VSETVLMAX_EXIT:%.*]]
// RV32-FIXED:       while.body.i:
// RV32-FIXED-NEXT:    [[LEN_ADDR_012_I:%.*]] = phi i32 [ [[SUB_I:%.*]], [[WHILE_BODY_I]] ], [ [[LEN]], [[ENTRY:%.*]] ]
// RV32-FIXED-NEXT:    [[PTR_011_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[WHILE_BODY_I]] ], [ [[DATA:%.*]], [[ENTRY]] ]
// RV32-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_011_I]], i32 16)
// RV32-FIXED-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_011_I]], i32 16
// RV32-FIXED-NEXT:    [[SUB_I]] = add i32 [[LEN_ADDR_012_I]], -16
// RV32-FIXED-NEXT:    [[CMP_I:%.*]] = icmp ugt i32 [[SUB_I]], 16
// RV32-FIXED-NEXT:    br i1 [[CMP_I]], label [[WHILE_BODY_I]], label [[TEST_VSETVLMAX_EXIT]], !llvm.loop [[LOOP4:![0-9]+]]
// RV32-FIXED:       test_vsetvlmax.exit:
// RV32-FIXED-NEXT:    [[PTR_0_LCSSA_I:%.*]] = phi ptr [ [[DATA]], [[ENTRY]] ], [ [[ADD_PTR_I]], [[WHILE_BODY_I]] ]
// RV32-FIXED-NEXT:    [[LEN_ADDR_0_LCSSA_I:%.*]] = phi i32 [ [[LEN]], [[ENTRY]] ], [ [[SUB_I]], [[WHILE_BODY_I]] ]
// RV32-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_0_LCSSA_I]], i32 [[LEN_ADDR_0_LCSSA_I]])
// RV32-FIXED-NEXT:    ret void
//
// RV64-FIXED-LABEL: @test_vsetvlmax_agnostic_vl(
// RV64-FIXED-NEXT:  entry:
// RV64-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvlimax.i64(i64 0, i64 0)
// RV64-FIXED-NEXT:    [[TMP0:%.*]] = icmp eq i64 [[VL1_I]], 16
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV64-FIXED-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 16)
// RV64-FIXED-NEXT:    [[CMP10_I:%.*]] = icmp ugt i64 [[LEN:%.*]], 16
// RV64-FIXED-NEXT:    br i1 [[CMP10_I]], label [[WHILE_BODY_I:%.*]], label [[TEST_VSETVLMAX_EXIT:%.*]]
// RV64-FIXED:       while.body.i:
// RV64-FIXED-NEXT:    [[LEN_ADDR_012_I:%.*]] = phi i64 [ [[SUB_I:%.*]], [[WHILE_BODY_I]] ], [ [[LEN]], [[ENTRY:%.*]] ]
// RV64-FIXED-NEXT:    [[PTR_011_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[WHILE_BODY_I]] ], [ [[DATA:%.*]], [[ENTRY]] ]
// RV64-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_011_I]], i64 16)
// RV64-FIXED-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_011_I]], i64 16
// RV64-FIXED-NEXT:    [[SUB_I]] = add i64 [[LEN_ADDR_012_I]], -16
// RV64-FIXED-NEXT:    [[CMP_I:%.*]] = icmp ugt i64 [[SUB_I]], 16
// RV64-FIXED-NEXT:    br i1 [[CMP_I]], label [[WHILE_BODY_I]], label [[TEST_VSETVLMAX_EXIT]], !llvm.loop [[LOOP4:![0-9]+]]
// RV64-FIXED:       test_vsetvlmax.exit:
// RV64-FIXED-NEXT:    [[PTR_0_LCSSA_I:%.*]] = phi ptr [ [[DATA]], [[ENTRY]] ], [ [[ADD_PTR_I]], [[WHILE_BODY_I]] ]
// RV64-FIXED-NEXT:    [[LEN_ADDR_0_LCSSA_I:%.*]] = phi i64 [ [[LEN]], [[ENTRY]] ], [ [[SUB_I]], [[WHILE_BODY_I]] ]
// RV64-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[PTR_0_LCSSA_I]], i64 [[LEN_ADDR_0_LCSSA_I]])
// RV64-FIXED-NEXT:    ret void
//
void test_vsetvlmax_agnostic_vl(void *data, size_t len) { test_vsetvlmax(data, len); }

// RV32-LABEL: @test_vsetvli_known_vl(
// RV32-NEXT:  assumption_end4.i:
// RV32-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 8, i32 0, i32 0)
// RV32-NEXT:    [[TMP0:%.*]] = icmp eq i32 [[VL1_I]], 8
// RV32-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV32-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 8)
// RV32-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i32 8)
// RV32-NEXT:    [[VL2_I:%.*]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 0, i32 0, i32 0)
// RV32-NEXT:    [[TMP2:%.*]] = icmp eq i32 [[VL2_I]], 0
// RV32-NEXT:    tail call void @llvm.assume(i1 [[TMP2]])
// RV32-NEXT:    ret void
//
// RV64-LABEL: @test_vsetvli_known_vl(
// RV64-NEXT:  assumption_end4.i:
// RV64-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 8, i64 0, i64 0)
// RV64-NEXT:    [[TMP0:%.*]] = icmp eq i64 [[VL1_I]], 8
// RV64-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV64-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 8)
// RV64-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i64 8)
// RV64-NEXT:    [[VL2_I:%.*]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 0, i64 0, i64 0)
// RV64-NEXT:    [[TMP2:%.*]] = icmp eq i64 [[VL2_I]], 0
// RV64-NEXT:    tail call void @llvm.assume(i1 [[TMP2]])
// RV64-NEXT:    ret void
//
// RV32-FIXED-LABEL: @test_vsetvli_known_vl(
// RV32-FIXED-NEXT:  assumption_end4.i:
// RV32-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 8, i32 0, i32 0)
// RV32-FIXED-NEXT:    [[TMP0:%.*]] = icmp eq i32 [[VL1_I]], 8
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV32-FIXED-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 8)
// RV32-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i32 8)
// RV32-FIXED-NEXT:    [[VL2_I:%.*]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 0, i32 0, i32 0)
// RV32-FIXED-NEXT:    [[TMP2:%.*]] = icmp eq i32 [[VL2_I]], 0
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP2]])
// RV32-FIXED-NEXT:    ret void
//
// RV64-FIXED-LABEL: @test_vsetvli_known_vl(
// RV64-FIXED-NEXT:  assumption_end4.i:
// RV64-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 8, i64 0, i64 0)
// RV64-FIXED-NEXT:    [[TMP0:%.*]] = icmp eq i64 [[VL1_I]], 8
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP0]])
// RV64-FIXED-NEXT:    [[TMP1:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 8)
// RV64-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP1]], ptr [[DATA:%.*]], i64 8)
// RV64-FIXED-NEXT:    [[VL2_I:%.*]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 0, i64 0, i64 0)
// RV64-FIXED-NEXT:    [[TMP2:%.*]] = icmp eq i64 [[VL2_I]], 0
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP2]])
// RV64-FIXED-NEXT:    ret void
//
void test_vsetvli_known_vl(uint64_t* data) { test_vsetvli(data, sizeof(uint64_t)); }

// RV32-LABEL: @test_vsetvli_agnostic_vl(
// RV32-NEXT:  entry:
// RV32-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 [[LEN:%.*]], i32 0, i32 0)
// RV32-NEXT:    [[TMP0:%.*]] = icmp ult i32 [[LEN]], 17
// RV32-NEXT:    br i1 [[TMP0]], label [[ASSUMPTION_END_I:%.*]], label [[WHILE_BODY_I_PREHEADER:%.*]]
// RV32:       assumption_end.i:
// RV32-NEXT:    [[TMP1:%.*]] = icmp eq i32 [[VL1_I]], [[LEN]]
// RV32-NEXT:    tail call void @llvm.assume(i1 [[TMP1]])
// RV32-NEXT:    [[CMP_NOT12_I:%.*]] = icmp eq i32 [[LEN]], 0
// RV32-NEXT:    br i1 [[CMP_NOT12_I]], label [[TEST_VSETVLI_EXIT:%.*]], label [[WHILE_BODY_I_PREHEADER]]
// RV32:       while.body.i.preheader:
// RV32-NEXT:    br label [[WHILE_BODY_I:%.*]]
// RV32:       while.body.i:
// RV32-NEXT:    [[LEN_ADDR_015_I:%.*]] = phi i32 [ [[SUB_I:%.*]], [[ASSUMPTION_END4_I:%.*]] ], [ [[LEN]], [[WHILE_BODY_I_PREHEADER]] ]
// RV32-NEXT:    [[VL_014_I:%.*]] = phi i32 [ [[VL2_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[VL1_I]], [[WHILE_BODY_I_PREHEADER]] ]
// RV32-NEXT:    [[PTR_013_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[DATA:%.*]], [[WHILE_BODY_I_PREHEADER]] ]
// RV32-NEXT:    [[TMP2:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 [[VL_014_I]])
// RV32-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP2]], ptr [[PTR_013_I]], i32 [[VL_014_I]])
// RV32-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_013_I]], i32 [[VL_014_I]]
// RV32-NEXT:    [[SUB_I]] = sub i32 [[LEN_ADDR_015_I]], [[VL_014_I]]
// RV32-NEXT:    [[VL2_I]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 [[SUB_I]], i32 0, i32 0)
// RV32-NEXT:    [[TMP3:%.*]] = icmp ult i32 [[SUB_I]], 17
// RV32-NEXT:    br i1 [[TMP3]], label [[ASSUMPTION3_I:%.*]], label [[ASSUMPTION_END4_I]]
// RV32:       assumption3.i:
// RV32-NEXT:    [[TMP4:%.*]] = icmp eq i32 [[VL2_I]], [[SUB_I]]
// RV32-NEXT:    tail call void @llvm.assume(i1 [[TMP4]])
// RV32-NEXT:    br label [[ASSUMPTION_END4_I]]
// RV32:       assumption_end4.i:
// RV32-NEXT:    [[CMP_NOT_I:%.*]] = icmp eq i32 [[SUB_I]], 0
// RV32-NEXT:    br i1 [[CMP_NOT_I]], label [[TEST_VSETVLI_EXIT]], label [[WHILE_BODY_I]], !llvm.loop [[LOOP6:![0-9]+]]
// RV32:       test_vsetvli.exit:
// RV32-NEXT:    ret void
//
// RV64-LABEL: @test_vsetvli_agnostic_vl(
// RV64-NEXT:  entry:
// RV64-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 [[LEN:%.*]], i64 0, i64 0)
// RV64-NEXT:    [[TMP0:%.*]] = icmp ult i64 [[LEN]], 17
// RV64-NEXT:    br i1 [[TMP0]], label [[ASSUMPTION_END_I:%.*]], label [[WHILE_BODY_I_PREHEADER:%.*]]
// RV64:       assumption_end.i:
// RV64-NEXT:    [[TMP1:%.*]] = icmp eq i64 [[VL1_I]], [[LEN]]
// RV64-NEXT:    tail call void @llvm.assume(i1 [[TMP1]])
// RV64-NEXT:    [[CMP_NOT12_I:%.*]] = icmp eq i64 [[LEN]], 0
// RV64-NEXT:    br i1 [[CMP_NOT12_I]], label [[TEST_VSETVLI_EXIT:%.*]], label [[WHILE_BODY_I_PREHEADER]]
// RV64:       while.body.i.preheader:
// RV64-NEXT:    br label [[WHILE_BODY_I:%.*]]
// RV64:       while.body.i:
// RV64-NEXT:    [[LEN_ADDR_015_I:%.*]] = phi i64 [ [[SUB_I:%.*]], [[ASSUMPTION_END4_I:%.*]] ], [ [[LEN]], [[WHILE_BODY_I_PREHEADER]] ]
// RV64-NEXT:    [[VL_014_I:%.*]] = phi i64 [ [[VL2_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[VL1_I]], [[WHILE_BODY_I_PREHEADER]] ]
// RV64-NEXT:    [[PTR_013_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[DATA:%.*]], [[WHILE_BODY_I_PREHEADER]] ]
// RV64-NEXT:    [[TMP2:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 [[VL_014_I]])
// RV64-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP2]], ptr [[PTR_013_I]], i64 [[VL_014_I]])
// RV64-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_013_I]], i64 [[VL_014_I]]
// RV64-NEXT:    [[SUB_I]] = sub i64 [[LEN_ADDR_015_I]], [[VL_014_I]]
// RV64-NEXT:    [[VL2_I]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 [[SUB_I]], i64 0, i64 0)
// RV64-NEXT:    [[TMP3:%.*]] = icmp ult i64 [[SUB_I]], 17
// RV64-NEXT:    br i1 [[TMP3]], label [[ASSUMPTION3_I:%.*]], label [[ASSUMPTION_END4_I]]
// RV64:       assumption3.i:
// RV64-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[VL2_I]], [[SUB_I]]
// RV64-NEXT:    tail call void @llvm.assume(i1 [[TMP4]])
// RV64-NEXT:    br label [[ASSUMPTION_END4_I]]
// RV64:       assumption_end4.i:
// RV64-NEXT:    [[CMP_NOT_I:%.*]] = icmp eq i64 [[SUB_I]], 0
// RV64-NEXT:    br i1 [[CMP_NOT_I]], label [[TEST_VSETVLI_EXIT]], label [[WHILE_BODY_I]], !llvm.loop [[LOOP6:![0-9]+]]
// RV64:       test_vsetvli.exit:
// RV64-NEXT:    ret void
//
// RV32-FIXED-LABEL: @test_vsetvli_agnostic_vl(
// RV32-FIXED-NEXT:  entry:
// RV32-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 [[LEN:%.*]], i32 0, i32 0)
// RV32-FIXED-NEXT:    [[TMP0:%.*]] = icmp ult i32 [[LEN]], 17
// RV32-FIXED-NEXT:    br i1 [[TMP0]], label [[ASSUMPTION_END_I:%.*]], label [[ASSUMPTION_END_THREAD_I:%.*]]
// RV32-FIXED:       assumption_end.thread.i:
// RV32-FIXED-NEXT:    [[TMP1:%.*]] = icmp ult i32 [[LEN]], 32
// RV32-FIXED-NEXT:    [[TMP2:%.*]] = icmp eq i32 [[VL1_I]], 16
// RV32-FIXED-NEXT:    [[TMP3:%.*]] = select i1 [[TMP1]], i1 true, i1 [[TMP2]]
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP3]])
// RV32-FIXED-NEXT:    br label [[WHILE_BODY_I_PREHEADER:%.*]]
// RV32-FIXED:       assumption_end.i:
// RV32-FIXED-NEXT:    [[TMP4:%.*]] = icmp eq i32 [[VL1_I]], [[LEN]]
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP4]])
// RV32-FIXED-NEXT:    [[CMP_NOT12_I:%.*]] = icmp eq i32 [[LEN]], 0
// RV32-FIXED-NEXT:    br i1 [[CMP_NOT12_I]], label [[TEST_VSETVLI_EXIT:%.*]], label [[WHILE_BODY_I_PREHEADER]]
// RV32-FIXED:       while.body.i.preheader:
// RV32-FIXED-NEXT:    br label [[WHILE_BODY_I:%.*]]
// RV32-FIXED:       while.body.i:
// RV32-FIXED-NEXT:    [[LEN_ADDR_015_I:%.*]] = phi i32 [ [[SUB_I:%.*]], [[ASSUMPTION_END4_I:%.*]] ], [ [[LEN]], [[WHILE_BODY_I_PREHEADER]] ]
// RV32-FIXED-NEXT:    [[VL_014_I:%.*]] = phi i32 [ [[VL2_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[VL1_I]], [[WHILE_BODY_I_PREHEADER]] ]
// RV32-FIXED-NEXT:    [[PTR_013_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[DATA:%.*]], [[WHILE_BODY_I_PREHEADER]] ]
// RV32-FIXED-NEXT:    [[TMP5:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i32(<vscale x 8 x i8> poison, i8 0, i32 [[VL_014_I]])
// RV32-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i32(<vscale x 8 x i8> [[TMP5]], ptr [[PTR_013_I]], i32 [[VL_014_I]])
// RV32-FIXED-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_013_I]], i32 [[VL_014_I]]
// RV32-FIXED-NEXT:    [[SUB_I]] = sub i32 [[LEN_ADDR_015_I]], [[VL_014_I]]
// RV32-FIXED-NEXT:    [[VL2_I]] = tail call i32 @llvm.riscv.vsetvli.i32(i32 [[SUB_I]], i32 0, i32 0)
// RV32-FIXED-NEXT:    [[TMP6:%.*]] = icmp ult i32 [[SUB_I]], 17
// RV32-FIXED-NEXT:    br i1 [[TMP6]], label [[ASSUMPTION3_I:%.*]], label [[ASSUMPTION_END4_I]]
// RV32-FIXED:       assumption3.i:
// RV32-FIXED-NEXT:    [[TMP7:%.*]] = icmp eq i32 [[VL2_I]], [[SUB_I]]
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP7]])
// RV32-FIXED-NEXT:    br label [[ASSUMPTION_END4_I]]
// RV32-FIXED:       assumption_end4.i:
// RV32-FIXED-NEXT:    [[TMP8:%.*]] = icmp ult i32 [[SUB_I]], 32
// RV32-FIXED-NEXT:    [[TMP9:%.*]] = icmp eq i32 [[VL2_I]], 16
// RV32-FIXED-NEXT:    [[TMP10:%.*]] = select i1 [[TMP8]], i1 true, i1 [[TMP9]]
// RV32-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP10]])
// RV32-FIXED-NEXT:    [[CMP_NOT_I:%.*]] = icmp eq i32 [[SUB_I]], 0
// RV32-FIXED-NEXT:    br i1 [[CMP_NOT_I]], label [[TEST_VSETVLI_EXIT]], label [[WHILE_BODY_I]], !llvm.loop [[LOOP6:![0-9]+]]
// RV32-FIXED:       test_vsetvli.exit:
// RV32-FIXED-NEXT:    ret void
//
// RV64-FIXED-LABEL: @test_vsetvli_agnostic_vl(
// RV64-FIXED-NEXT:  entry:
// RV64-FIXED-NEXT:    [[VL1_I:%.*]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 [[LEN:%.*]], i64 0, i64 0)
// RV64-FIXED-NEXT:    [[TMP0:%.*]] = icmp ult i64 [[LEN]], 17
// RV64-FIXED-NEXT:    br i1 [[TMP0]], label [[ASSUMPTION_END_I:%.*]], label [[ASSUMPTION_END_THREAD_I:%.*]]
// RV64-FIXED:       assumption_end.thread.i:
// RV64-FIXED-NEXT:    [[TMP1:%.*]] = icmp ult i64 [[LEN]], 32
// RV64-FIXED-NEXT:    [[TMP2:%.*]] = icmp eq i64 [[VL1_I]], 16
// RV64-FIXED-NEXT:    [[TMP3:%.*]] = select i1 [[TMP1]], i1 true, i1 [[TMP2]]
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP3]])
// RV64-FIXED-NEXT:    br label [[WHILE_BODY_I_PREHEADER:%.*]]
// RV64-FIXED:       assumption_end.i:
// RV64-FIXED-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[VL1_I]], [[LEN]]
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP4]])
// RV64-FIXED-NEXT:    [[CMP_NOT12_I:%.*]] = icmp eq i64 [[LEN]], 0
// RV64-FIXED-NEXT:    br i1 [[CMP_NOT12_I]], label [[TEST_VSETVLI_EXIT:%.*]], label [[WHILE_BODY_I_PREHEADER]]
// RV64-FIXED:       while.body.i.preheader:
// RV64-FIXED-NEXT:    br label [[WHILE_BODY_I:%.*]]
// RV64-FIXED:       while.body.i:
// RV64-FIXED-NEXT:    [[LEN_ADDR_015_I:%.*]] = phi i64 [ [[SUB_I:%.*]], [[ASSUMPTION_END4_I:%.*]] ], [ [[LEN]], [[WHILE_BODY_I_PREHEADER]] ]
// RV64-FIXED-NEXT:    [[VL_014_I:%.*]] = phi i64 [ [[VL2_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[VL1_I]], [[WHILE_BODY_I_PREHEADER]] ]
// RV64-FIXED-NEXT:    [[PTR_013_I:%.*]] = phi ptr [ [[ADD_PTR_I:%.*]], [[ASSUMPTION_END4_I]] ], [ [[DATA:%.*]], [[WHILE_BODY_I_PREHEADER]] ]
// RV64-FIXED-NEXT:    [[TMP5:%.*]] = tail call <vscale x 8 x i8> @llvm.riscv.vmv.v.x.nxv8i8.i64(<vscale x 8 x i8> poison, i8 0, i64 [[VL_014_I]])
// RV64-FIXED-NEXT:    tail call void @llvm.riscv.vse.nxv8i8.i64(<vscale x 8 x i8> [[TMP5]], ptr [[PTR_013_I]], i64 [[VL_014_I]])
// RV64-FIXED-NEXT:    [[ADD_PTR_I]] = getelementptr inbounds i8, ptr [[PTR_013_I]], i64 [[VL_014_I]]
// RV64-FIXED-NEXT:    [[SUB_I]] = sub i64 [[LEN_ADDR_015_I]], [[VL_014_I]]
// RV64-FIXED-NEXT:    [[VL2_I]] = tail call i64 @llvm.riscv.vsetvli.i64(i64 [[SUB_I]], i64 0, i64 0)
// RV64-FIXED-NEXT:    [[TMP6:%.*]] = icmp ult i64 [[SUB_I]], 17
// RV64-FIXED-NEXT:    br i1 [[TMP6]], label [[ASSUMPTION3_I:%.*]], label [[ASSUMPTION_END4_I]]
// RV64-FIXED:       assumption3.i:
// RV64-FIXED-NEXT:    [[TMP7:%.*]] = icmp eq i64 [[VL2_I]], [[SUB_I]]
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP7]])
// RV64-FIXED-NEXT:    br label [[ASSUMPTION_END4_I]]
// RV64-FIXED:       assumption_end4.i:
// RV64-FIXED-NEXT:    [[TMP8:%.*]] = icmp ult i64 [[SUB_I]], 32
// RV64-FIXED-NEXT:    [[TMP9:%.*]] = icmp eq i64 [[VL2_I]], 16
// RV64-FIXED-NEXT:    [[TMP10:%.*]] = select i1 [[TMP8]], i1 true, i1 [[TMP9]]
// RV64-FIXED-NEXT:    tail call void @llvm.assume(i1 [[TMP10]])
// RV64-FIXED-NEXT:    [[CMP_NOT_I:%.*]] = icmp eq i64 [[SUB_I]], 0
// RV64-FIXED-NEXT:    br i1 [[CMP_NOT_I]], label [[TEST_VSETVLI_EXIT]], label [[WHILE_BODY_I]], !llvm.loop [[LOOP6:![0-9]+]]
// RV64-FIXED:       test_vsetvli.exit:
// RV64-FIXED-NEXT:    ret void
//
void test_vsetvli_agnostic_vl(void *data, size_t len) { test_vsetvli(data, len); }
